{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67d15f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joshua Schmidt\n",
      "\n",
      "SOFTWARE ENGINEER @ GOOGLE\n",
      "\n",
      "(cid:83) New York, NY | (cid:260) +1 (908) 531-7087 | (cid:229) jns223@cornell.edu | (cid:83) joshuaschmidt.tech | (cid:69) jschmidtnj\n",
      "\n",
      "| (cid:68) joshua-n-schmidt\n",
      "\n",
      "Education\n",
      "Cornell Tech\n",
      "\n",
      "MASTER OF ENGINEERING IN COMPUTER SCIENCE\n",
      "\n",
      "New York, NY\n",
      "\n",
      "May 2022\n",
      "\n",
      "CONCENTRATION: Machine Learning · Merit Scholarship · COURSES: Machine Learning Engineering, AR & VR, Designing Interactive Devices\n",
      "\n",
      "Stevens Institute of Technology\n",
      "\n",
      "BACHELOR OF ENGINEERING IN COMPUTER ENGINEERING\n",
      "\n",
      "Hoboken, NJ\n",
      "\n",
      "May 2021\n",
      "\n",
      "MINOR: Computer Science · Highest Honors · COURSES: Data Structures, Advanced Algorithms, NLP, Systems Programming\n",
      "\n",
      "Technical Skills\n",
      "\n",
      "Languages\n",
      "Tools / Libraries\n",
      "\n",
      "C++, Python, Node.js, Go, Java, C#, C\n",
      "Tensorflow, PyTorch, Huggingface, Colab, ProtoBuffs, OpenCV, ROS, Docker, Springboot, Unity, LATEX, MQTT\n",
      "\n",
      "Web / OS TypeScript, JavaScript, Next.js, HTML, CSS, React.js, Vue.js · Linux — Debian and Arch based, MacOS\n",
      "\n",
      "DB / Cloud MongoDB, Spanner, PostgreSQL, Redis, Elasticsearch · AWS, GCP, Netlify, Firebase, Heroku, Kubernetes, Serverless, CI/CD\n",
      "\n",
      "Experience\n",
      "\n",
      "Google\n",
      "\n",
      "New York, NY\n",
      "\n",
      "SOFTWARE ENGINEER, PLAY STORE\n",
      "Aug 2022 - Present\n",
      "• Added support for indexing fresh, personalized YouTube developer videos on the Play Store, which increased user engagement by over 30% on\n",
      "\n",
      "certain surfaces, driving app installs and increasing revenue.\n",
      "\n",
      "• Worked on projects incorporating LLM-generated content, specifically from Bard and Gemini, in new content experiences on the Play Store.\n",
      "• Designed and implemented the Short Form Video Cluster backend, which surfaces YouTube Shorts on the Play Store.\n",
      "\n",
      "NASA Langley Research Center\n",
      "\n",
      "Langley, Virginia\n",
      "\n",
      "ASSEMBLERS SOFTWARE INTERNSHIP\n",
      "May 2021 - Aug. 2021\n",
      "• Created a Software in the Loop Simulation of the Assemblers robot, incorporating a physics engine and a real-time messaging service (DDS).\n",
      "Developed simulations of all hardware components, including joint controllers, the IMU, and cameras, all fully interoperable with real hardware.\n",
      "• Designed and implemented a user interface for visualizing and recording the simulation. Used 3D models of the modular Stewart platforms\n",
      "to accurately display the robot interacting with elements on the lunar surface. This desktop application was built with Qt, Python, and C++.\n",
      "Integrated with the trajectory generator and executor to show log messages in the UI.\n",
      "\n",
      "U.S. Census Bureau\n",
      "\n",
      "Washington, D.C.\n",
      "\n",
      "CIVIC DIGITAL FELLOWSHIP, SOFTWARE ENGINEER\n",
      "May. 2020 - Aug. 2020\n",
      "• Engineered an NLP system for extracting and parsing pseudocode from 500+ page text documents, converting to an abstract object-oriented\n",
      "\n",
      "hierarchy. Processed this datastructure to generate executable Python code, used to validate decennial census data.\n",
      "\n",
      "• Developed a REST service in Python to proxy requests to the Spark and Spark History UI, enabling access without ssh forwarding. Used bs4\n",
      "to parse HTML and rewrite URL paths. Created reports and visualizations for Differential Privacy System executions, accessible in an internal\n",
      "dashboard.\n",
      "\n",
      "Nokia Bell Labs\n",
      "\n",
      "Murray Hill, NJ\n",
      "\n",
      "ROBOTICS DEVELOPMENT INTERNSHIP\n",
      "May 2019 - Aug. 2019\n",
      "• Upgraded swerve drive robot platform to navigate autonomously, using ROS to handle data processing. Required substantial changes in hard-\n",
      "\n",
      "•\n",
      "\n",
      "ware and software, with new motorcontrollers, motors, microprocessors, and kinematics software.\n",
      "Integrated onboard drivetrain control software developed in C++ and Python, utilizing odometry data from onboard encoders, LIDAR, computer\n",
      "vision and an IMU. New modular design enables hot-swapping sensors and end effectors.\n",
      "\n",
      "Projects\n",
      "\n",
      "FlexApp AI\n",
      "\n",
      "New York, NY\n",
      "\n",
      "RENTAL APPLICATION AUTOMATION TOOL\n",
      "Dec. 2021 - June 2022\n",
      "• Cofounder of FlexApp, a tool that makes it easy for prospective renters to apply for apartments, and property managers to review applications.\n",
      "• Lead developer of five-person team, created novel AI tools that read PDFs and converted the text to and from consistent formats, solving a major\n",
      "\n",
      "pain-point for both applicants and realtors.\n",
      "\n",
      "• Created a React & Next.js based web app deployed to AWS for managing applications and making the submittion process as seamless as possible,\n",
      "\n",
      "with one-click applications.\n",
      "\n",
      "• Built AI models for matching applicants with the best rentals for their credit history and financial constraints. Created tools for interfacing with\n",
      "\n",
      "Plaid and banking data, to support renters who are under-banked.\n",
      "\n",
      "UPDATED DECEMBER 27, 2023\n",
      "\n",
      "JOSHUA SCHMIDT · RESUME\n",
      "\n",
      "1\n",
      "\n",
      "\f",
      "SSMIF\n",
      "\n",
      "Hoboken, NJ\n",
      "\n",
      "STEVENS STUDENT MANAGED INVESTMENT FUND\n",
      "• Lead developer of a team of 15 quantitative analysts and software engineers managing an endowment fund worth over $700k.\n",
      "• Created a factor model for analyzing past and projected performance of the fund. Leverages several ML models — Arima Regression, Random\n",
      "\n",
      "Aug. 2020 - May 2021\n",
      "\n",
      "Forest, Attention-based Neural Networks — built with Tensorflow and Scikit learn using C++ and Python.\n",
      "\n",
      "• Built a React & Next.js based web app deployed to AWS for executing transactions, visualizing performance, and running the factor model.\n",
      "• Developed Lambda functions to automate fetching & analyzing ticker data, generating excel reports, and running GitHub Actions CI / CD updates.\n",
      "\n",
      "reScribe\n",
      "\n",
      "Hoboken, NJ\n",
      "\n",
      "A BETTER WAY TO SEARCH FOR CODE\n",
      "• Software development lead, working with 5 designers and engineers to build the most advanced source code search and analysis tool.\n",
      "• Created a scalable, NLP-based algorithm for indexing open-source code. Used ANTLR4 to parse code syntax, and integrated with Elasticsearch.\n",
      "• Designed a public authenticated GraphQL API for integrating with client-facing applications, including a first-party web app (created using\n",
      "\n",
      "Oct. 2020 - July 2021\n",
      "\n",
      "Gatsby), VSCode extension, and GitHub App (for CI/CD integration). Over 10k repositories indexed.\n",
      "\n",
      "UPDATED DECEMBER 27, 2023\n",
      "\n",
      "JOSHUA SCHMIDT · RESUME\n",
      "\n",
      "2\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    " \n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    print(extract_text_from_pdf(\"/Users/abhivesh/Abhivesh/Resume Parser/Joshua.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c5dea",
   "metadata": {},
   "source": [
    "### Extracting Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82355882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Joshua Schmidt\n"
     ]
    }
   ],
   "source": [
    "import pdfminer\n",
    "import re\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "def extract_name_from_resume(text):\n",
    "    name = None\n",
    "\n",
    "    # Use regex pattern to find a potential name\n",
    "    pattern = r\"(\\b[A-Z][a-z]+\\b)\\s(\\b[A-Z][a-z]+\\b)\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        name = match.group()\n",
    "\n",
    "    return name\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_pdf(\"/Users/abhivesh/Abhivesh/Resume Parser/Joshua.pdf\")\n",
    "    name = extract_name_from_resume(text)\n",
    "\n",
    "    if name:\n",
    "        print(\"Name:\", name)\n",
    "    else:\n",
    "        print(\"Name not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3bab8",
   "metadata": {},
   "source": [
    "### Extracting Contact Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1ea1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact Number: 1 (908) 531-7087\n"
     ]
    }
   ],
   "source": [
    " def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "def extract_contact_number_from_resume(text):\n",
    "    contact_number = None\n",
    "\n",
    "    # Use regex pattern to find a potential contact number\n",
    "    pattern = r\"\\b(?:\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        contact_number = match.group()\n",
    "\n",
    "    return contact_number\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_pdf(\"/Users/abhivesh/Abhivesh/Resume Parser/Joshua.pdf\")\n",
    "    contact_number = extract_contact_number_from_resume(text)\n",
    "\n",
    "    if contact_number:\n",
    "        print(\"Contact Number:\", contact_number)\n",
    "    else:\n",
    "        print(\"Contact Number not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3a11e5",
   "metadata": {},
   "source": [
    "### Extracting Email ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f0f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: jns223@cornell.edu\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "def extract_email_from_resume(text):\n",
    "    email = None\n",
    "\n",
    "    # Use regex pattern to find a potential email address\n",
    "    pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        email = match.group()\n",
    "\n",
    "    return email\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_pdf(\"/Users/abhivesh/Abhivesh/Resume Parser/Joshua.pdf\")\n",
    "    email = extract_email_from_resume(text)\n",
    "\n",
    "    if email:\n",
    "        print(\"Email:\", email)\n",
    "    else:\n",
    "        print(\"Email not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d05ab8",
   "metadata": {},
   "source": [
    "### Extracting Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90a413b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills Section Identified:\n",
      " Languages:\n",
      "Tools / Libraries\n",
      "\n",
      "Web / OS:\n",
      "TypeScript, JavaScript, Next.js, HTML, CSS, React.js, Vue.js · Linux — Debian and Arch based, MacOS\n",
      "\n",
      "DB / Cloud:\n",
      "MongoDB, Spanner, PostgreSQL, Redis, Elasticsearch · AWS, GCP, Netlify, Firebase, Heroku, Kubernetes, Serverless, CI/CD\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "def identify_skills_section(text):\n",
    "    \"\"\"Identifies potential skills sections in the text based on specific keywords.\"\"\"\n",
    "    # Regex pattern to capture sections under specific headers\n",
    "    pattern = r\"(?i)(languages|tools / libraries|web / os|db / cloud)[:\\s\\n]*([\\s\\S]*?)(?=\\n\\n|\\n(?:languages|tools / libraries|web / os|db / cloud|education|experience|projects|work|achievements?|$))\"\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    combined_skills_section = \"\"\n",
    "    \n",
    "    # Combine all matched sections into a single string\n",
    "    for match in matches:\n",
    "        header, content = match\n",
    "        combined_skills_section += f\"{header}:\\n{content.strip()}\\n\\n\"\n",
    "\n",
    "    return combined_skills_section\n",
    "\n",
    "def extract_possible_skills(section_text):\n",
    "    \"\"\"Extracts potential skills from the skills section text.\"\"\"\n",
    "    # Clean text for more accurate extraction\n",
    "    section_text = re.sub(r'[^a-zA-Z\\s]', ' ', section_text)\n",
    "    \n",
    "    # Use CountVectorizer to identify potential skills\n",
    "    vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "    X = vectorizer.fit_transform([section_text])\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Return terms sorted by frequency\n",
    "    term_frequency = X.sum(axis=0).A1\n",
    "    term_freq_dict = dict(zip(terms, term_frequency))\n",
    "    \n",
    "    # Filter terms that appear more than once\n",
    "    possible_skills = [term for term, freq in term_freq_dict.items() if freq > 1]\n",
    "    \n",
    "    return possible_skills\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pdf_path = \"/Users/abhivesh/Abhivesh/Resume Parser/Joshua.pdf\"\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # Identify the skills section from the resume\n",
    "    skills_section = identify_skills_section(text)\n",
    "\n",
    "    if skills_section:\n",
    "        print(\"Skills Section Identified:\\n\", skills_section)\n",
    "        # Extract potential skills from the identified skills section\n",
    "        possible_skills = extract_possible_skills(skills_section)\n",
    "        \n",
    "    else:\n",
    "        print(\"No identifiable skills section found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90d019",
   "metadata": {},
   "source": [
    "### Extracting Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "085324be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education: ['MASTER OF ENGINEERING IN COMPUTER SCIENCE', 'BACHELOR OF ENGINEERING IN COMPUTER ENGINEERING']\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "def extract_education_from_resume(text):\n",
    "    education = []\n",
    "\n",
    "    # Use regex pattern to find education information\n",
    "    pattern = r\"(?i)(?:(?:Bachelor|B\\.S\\.|B\\.A\\.|Master|M\\.S\\.|M\\.A\\.|Ph\\.D\\.)\\s(?:[A-Za-z]+\\s)*[A-Za-z]+)\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    for match in matches:\n",
    "        education.append(match.strip())\n",
    "\n",
    "    return education\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_pdf(\"/Users/abhivesh/Abhivesh/Resume Parser/Joshua.pdf\")\n",
    "\n",
    "    extracted_education = extract_education_from_resume(text)\n",
    "    if extracted_education:\n",
    "        print(\"Education:\", extracted_education)\n",
    "    else:\n",
    "        print(\"No education information found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae0e84",
   "metadata": {},
   "source": [
    "### Extracting Work Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27470866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience\n",
      "\n",
      "Google\n",
      "\n",
      "New York, NY\n",
      "\n",
      "SOFTWARE ENGINEER, PLAY STORE\n",
      "Aug 2022 - Present\n",
      "• Added support for indexing fresh, personalized YouTube developer videos on the Play Store, which increased user engagement by over 30% on\n",
      "\n",
      "certain surfaces, driving app installs and increasing revenue.\n",
      "\n",
      "• Worked on\n",
      "--------------------------------------------------------------------------------\n",
      "experiences on the Play Store.\n",
      "• Designed and implemented the Short Form Video Cluster backend, which surfaces YouTube Shorts on the Play Store.\n",
      "\n",
      "NASA Langley Research Center\n",
      "\n",
      "Langley, Virginia\n",
      "\n",
      "ASSEMBLERS SOFTWARE INTERNSHIP\n",
      "May 2021 - Aug. 2021\n",
      "• Created a Software in the Loop Simulation of the Assemblers robot, incorporating a physics engine and a real-time messaging service (DDS).\n",
      "Developed simulations of all hardware components, including joint controllers, the IMU, and cameras, all fully interoperable with real hardware.\n",
      "• Designed and implemented a user interface for visualizing and recording the simulation. Used 3D models of the modular Stewart platforms\n",
      "to accurately display the robot interacting with elements on the lunar surface. This desktop application was built with Qt, Python, and C++.\n",
      "Integrated with the trajectory generator and executor to show log messages in the UI.\n",
      "\n",
      "U.S. Census Bureau\n",
      "\n",
      "Washington, D.C.\n",
      "\n",
      "CIVIC DIGITAL FELLOWSHIP, SOFTWARE ENGINEER\n",
      "May. 2020 - Aug. 2020\n",
      "• Engineered an NLP system for extracting and parsing pseudocode from 500+ page text documents, converting to an abstract object-oriented\n",
      "\n",
      "hierarchy. Processed this datastructure to generate executable Python code, used to validate decennial census data.\n",
      "\n",
      "• Developed a REST service in Python to proxy requests to the Spark and Spark History UI, enabling access without ssh forwarding. Used bs4\n",
      "to parse HTML and rewrite URL paths. Created reports and visualizations for Differential Privacy System executions, accessible in an internal\n",
      "dashboard.\n",
      "\n",
      "Nokia Bell Labs\n",
      "\n",
      "Murray Hill, NJ\n",
      "\n",
      "ROBOTICS DEVELOPMENT INTERNSHIP\n",
      "May 2019 - Aug. 2019\n",
      "• Upgraded swerve drive robot platform to navigate autonomously, using ROS to handle data processing. Required substantial changes in hard-\n",
      "\n",
      "•\n",
      "\n",
      "ware and software, with new motorcontrollers, motors, microprocessors, and kinematics software.\n",
      "Integrated onboard drivetrain control software developed in C++ and Python, utilizing odometry data from onboard encoders, LIDAR, computer\n",
      "vision and an IMU. New modular design enables hot-swapping sensors and end effectors.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import re\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "def extract_experience_from_resume(text):\n",
    "   \n",
    "    experiences = []\n",
    "\n",
    "    # Improved regex pattern to capture experience-related sections\n",
    "    pattern = r\"(?:Experience|Work Experience|Previous Jobs|Employment History|Job|Position)[\\s\\S]*?(?=(?:Education|Skills|Certification|Projects|$))\"\n",
    "    matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    for match in matches:\n",
    "        # Extract the section found\n",
    "        context = match.group().strip()\n",
    "        experiences.append(context)\n",
    "\n",
    "    return experiences\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pdf_path = \"/Users/abhivesh/Abhivesh/Resume Parser/Joshua.pdf\"\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    extracted_experiences = extract_experience_from_resume(text)\n",
    "\n",
    "    if extracted_experiences:\n",
    "\n",
    "        for exp in extracted_experiences:\n",
    "            print(exp)\n",
    "            print(\"-\" * 80)  \n",
    "    else:\n",
    "        print(\"No experience sections found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
